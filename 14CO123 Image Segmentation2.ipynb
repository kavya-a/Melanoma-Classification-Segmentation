{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, Input, concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adagrad, RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.core import Lambda\n",
    "import glob\n",
    "import cv2\n",
    "import itertools\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 2000\n",
    "gt_all = os.listdir('gt')\n",
    "\n",
    "X = np.zeros((batch_size,256,256,3))\n",
    "y = np.zeros((batch_size,256,256,3))\n",
    "for a in range(batch_size):\n",
    "    i = random.randint(0,len(gt_all)-1)\n",
    "\n",
    "    name = gt_all[i]\n",
    "    name = name.replace('_segmentation','')\n",
    "    name = name.replace('png','jpg')\n",
    "    img = cv2.imread(os.path.join('gt',gt_all[i]))\n",
    "    thresh = 127\n",
    "    img = cv2.resize(img,(256,256))\n",
    "    img = cv2.threshold(img, thresh, 1, cv2.THRESH_BINARY)[1]\n",
    "    y[a] = img\n",
    "    if name in os.listdir('melanoma'):\n",
    "        img = cv2.imread(os.path.join('melanoma',name))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img,(256,256))\n",
    "            X[a] = img\n",
    "    else:\n",
    "        img = cv2.imread(os.path.join('others',name))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img,(256,256))\n",
    "            X[a] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    \n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 10\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((256, 256, 3))\n",
    "\n",
    "conv1 = Conv2D(8, (3, 3), activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(8, (3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(16, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(up6)\n",
    "conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "conv8 = Conv2D(16, (3, 3), activation='relu', padding='same')(up8)\n",
    "conv8 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "conv9 = Conv2D(8, (3, 3), activation='relu', padding='same')(up9)\n",
    "conv9 = Conv2D(8, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[conv10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.2445 - dice_coef: 0.2445 - acc: 0.7978Epoch 00001: val_acc improved from -inf to 0.79755, saving model to segment.h5\n",
      "1280/1280 [==============================] - 120s 93ms/step - loss: -0.2456 - dice_coef: 0.2456 - acc: 0.7978 - val_loss: -0.4088 - val_dice_coef: 0.4088 - val_acc: 0.7975\n",
      "Epoch 2/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.4851 - dice_coef: 0.4851 - acc: 0.8283Epoch 00002: val_acc improved from 0.79755 to 0.85306, saving model to segment.h5\n",
      "1280/1280 [==============================] - 109s 85ms/step - loss: -0.4860 - dice_coef: 0.4860 - acc: 0.8288 - val_loss: -0.5407 - val_dice_coef: 0.5407 - val_acc: 0.8531\n",
      "Epoch 3/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.5771 - dice_coef: 0.5771 - acc: 0.8572Epoch 00003: val_acc improved from 0.85306 to 0.85980, saving model to segment.h5\n",
      "1280/1280 [==============================] - 106s 83ms/step - loss: -0.5785 - dice_coef: 0.5785 - acc: 0.8573 - val_loss: -0.6025 - val_dice_coef: 0.6025 - val_acc: 0.8598\n",
      "Epoch 4/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.6313 - dice_coef: 0.6313 - acc: 0.8718Epoch 00004: val_acc improved from 0.85980 to 0.86365, saving model to segment.h5\n",
      "1280/1280 [==============================] - 106s 83ms/step - loss: -0.6317 - dice_coef: 0.6317 - acc: 0.8718 - val_loss: -0.6334 - val_dice_coef: 0.6334 - val_acc: 0.8637\n",
      "Epoch 5/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.6573 - dice_coef: 0.6573 - acc: 0.8799Epoch 00005: val_acc improved from 0.86365 to 0.89141, saving model to segment.h5\n",
      "1280/1280 [==============================] - 111s 86ms/step - loss: -0.6574 - dice_coef: 0.6574 - acc: 0.8802 - val_loss: -0.6710 - val_dice_coef: 0.6710 - val_acc: 0.8914\n",
      "Epoch 6/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.6816 - dice_coef: 0.6816 - acc: 0.8912Epoch 00006: val_acc improved from 0.89141 to 0.89283, saving model to segment.h5\n",
      "1280/1280 [==============================] - 117s 91ms/step - loss: -0.6809 - dice_coef: 0.6809 - acc: 0.8909 - val_loss: -0.6877 - val_dice_coef: 0.6877 - val_acc: 0.8928\n",
      "Epoch 7/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.6981 - dice_coef: 0.6981 - acc: 0.8950Epoch 00007: val_acc improved from 0.89283 to 0.89532, saving model to segment.h5\n",
      "1280/1280 [==============================] - 119s 93ms/step - loss: -0.6984 - dice_coef: 0.6984 - acc: 0.8950 - val_loss: -0.6998 - val_dice_coef: 0.6998 - val_acc: 0.8953\n",
      "Epoch 8/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.7114 - dice_coef: 0.7114 - acc: 0.8992Epoch 00008: val_acc improved from 0.89532 to 0.89776, saving model to segment.h5\n",
      "1280/1280 [==============================] - 120s 94ms/step - loss: -0.7105 - dice_coef: 0.7105 - acc: 0.8990 - val_loss: -0.7100 - val_dice_coef: 0.7100 - val_acc: 0.8978\n",
      "Epoch 9/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.7170 - dice_coef: 0.7170 - acc: 0.9008Epoch 00009: val_acc improved from 0.89776 to 0.90637, saving model to segment.h5\n",
      "1280/1280 [==============================] - 108s 84ms/step - loss: -0.7169 - dice_coef: 0.7169 - acc: 0.9006 - val_loss: -0.7231 - val_dice_coef: 0.7231 - val_acc: 0.9064\n",
      "Epoch 10/10\n",
      "1270/1280 [============================>.] - ETA: 0s - loss: -0.7290 - dice_coef: 0.7290 - acc: 0.9022Epoch 00010: val_acc improved from 0.90637 to 0.90862, saving model to segment.h5\n",
      "1280/1280 [==============================] - 117s 91ms/step - loss: -0.7285 - dice_coef: 0.7285 - acc: 0.9023 - val_loss: -0.7297 - val_dice_coef: 0.7297 - val_acc: 0.9086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14b389278>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = dice_coef_loss, optimizer=Adam(lr=1e-5), metrics=[dice_coef, 'accuracy'])\n",
    "\n",
    "model.fit(segment_train_X, segment_train_Y, batch_size=batch_size, epochs = nb_epoch, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 11s 28ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(segment_test_X, segment_test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.6045227051\n"
     ]
    }
   ],
   "source": [
    "print(score[2] * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
